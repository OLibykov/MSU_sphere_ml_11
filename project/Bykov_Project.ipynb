{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c6528c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score, GridSearchCV\n",
    "from functools import partial\n",
    "from hyperopt import hp, tpe, Trials, STATUS_OK\n",
    "from hyperopt.fmin import fmin\n",
    "from hyperopt.pyll import scope\n",
    "from hyperopt.plotting import main_plot_history\n",
    "from catboost import CatBoostClassifier\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from nltk.stem.snowball import RussianStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee14a702",
   "metadata": {},
   "source": [
    "# Препроцессинг данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "970c1011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Олег\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "81ce2acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mystem = Mystem()\n",
    "mystem = RussianStemmer(False)\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "english_stopwords = stopwords.words(\"english\")\n",
    "not_word = []\n",
    "\n",
    "def is_word(token):\n",
    "    ok = False\n",
    "    legal_chars = '0123456789abcdefghijklmnopqrstuvwxyzабвгдеёжзийклмнопрстуфхцчшщъыьэюя'\n",
    "    for c in token:\n",
    "        if c not in legal_chars:\n",
    "            not_word.append(token)\n",
    "            return False\n",
    "        if c in '0123456789':\n",
    "            ok = True\n",
    "    \n",
    "    if len(token) <= 1 and not(ok):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def preprocess_text(text):\n",
    "    #tokens = mystem.lemmatize(text.lower())\n",
    "    data = mystem.stem(text.lower())\n",
    "    for sign in punctuation:\n",
    "        data = data.replace(sign, ' ')\n",
    "    data = data.replace('|', ' ')\n",
    "    data = data.replace('\"\\\"', ' ')\n",
    "    data = data.replace('-', ' ')\n",
    "    tokens = data.strip().split(' ')\n",
    "    tokens = [token.strip() for token in tokens if token not in russian_stopwords\\\n",
    "              and token not in english_stopwords\\\n",
    "              and token != \" \" \\\n",
    "              and token.strip() not in punctuation\n",
    "              and is_word(token)]\n",
    "    \n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7236a115",
   "metadata": {},
   "source": [
    "#### Пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dcefc68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({15731: 'ВАЗ 21213 | Замена подшипников ступицы | Нива',\n",
       "  14829: 'Ваз 2107 оптом в Сочи. Сравнить цены, купить потребительские товары на Tiu.ru',\n",
       "  15764: 'Купить ступица Лада калина2. Трансмиссия - переходные ступицы цена, замена, тюнинг.',\n",
       "  17669: 'Классика 21010 - 21074',\n",
       "  14852: 'Ступица Нива — замена подшипника своими руками'},\n",
       " {15731: 'ваз 21213 замена подшипников ступицы нив',\n",
       "  14829: 'ваз 2107 оптом сочи сравнить цены купить потребительские товары тиу',\n",
       "  15764: 'купить ступица лада калина2 трансмиссия переходные ступицы цена замена тюнинг',\n",
       "  17669: 'классика 21010 21074',\n",
       "  14852: 'ступица нива замена подшипника своими рук'})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_to_title = {}\n",
    "doc_proc_to_title = {}\n",
    "with open('docs_titles.tsv', encoding='utf-8') as f:\n",
    "    for num_line, line in enumerate(f):\n",
    "        if num_line == 0:\n",
    "            continue\n",
    "        data = line.strip().split('\\t', 1)\n",
    "        doc_id = int(data[0])\n",
    "        if len(data) == 1:\n",
    "            title = ''\n",
    "        else:\n",
    "            title = data[1]\n",
    "        doc_to_title[doc_id] = title# словарь: ID - title\n",
    "        doc_proc_to_title[doc_id] = preprocess_text(title)\n",
    "        if num_line == 5:\n",
    "            break\n",
    "doc_to_title, doc_proc_to_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe6496a",
   "metadata": {},
   "source": [
    "###### Мы можем наблюдать, как слова в заголовках привелись к нижнему регистру. Из текста удалены: предлоги, союзы и тд. - стоп слова; знаки препинания, пробелы, а также те слова, которые содержат не русские/английские буквы и цифры. Помимо этого слова приведены к словоформе с помощью леммитизации. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ca484d",
   "metadata": {},
   "source": [
    "### Попробуем применить эту модификацию текста и обучить модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c5d1de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_to_title = {}\n",
    "with open('docs_titles.tsv', encoding='utf-8') as f:\n",
    "    for num_line, line in enumerate(f):\n",
    "        if num_line == 0:\n",
    "            continue\n",
    "        data = line.strip().split('\\t', 1)\n",
    "        doc_id = int(data[0])\n",
    "        if len(data) == 1:\n",
    "            title = ''\n",
    "        else:\n",
    "            title = data[1]\n",
    "        doc_to_title[doc_id] = preprocess_text(title)# словарь: ID - title\n",
    "#doc_to_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56456f47",
   "metadata": {},
   "source": [
    "# Выделение признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8029ef2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('train_groups.csv')\n",
    "traingroups_titledata = {}\n",
    "for i in range(len(train_data)):\n",
    "    new_doc = train_data.iloc[i]\n",
    "    doc_group = new_doc['group_id']\n",
    "    doc_id = new_doc['doc_id']\n",
    "    target = new_doc['target']\n",
    "    title = doc_to_title[doc_id]\n",
    "    if doc_group not in traingroups_titledata:\n",
    "        traingroups_titledata[doc_group] = []\n",
    "    traingroups_titledata[doc_group].append((doc_id, title, target))# словарь: \n",
    "    # Group_ID - [(id - title - target),()...]\n",
    "#traingroups_titledata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8d7177a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_groups.csv')\n",
    "testgroups_titledata = {}\n",
    "for i in range(len(test_data)):\n",
    "    new_doc = test_data.iloc[i]\n",
    "    doc_group = new_doc['group_id']\n",
    "    doc_id = new_doc['doc_id']\n",
    "    title = doc_to_title[doc_id]\n",
    "    if doc_group not in testgroups_titledata:\n",
    "        testgroups_titledata[doc_group] = []\n",
    "    testgroups_titledata[doc_group].append((doc_id, title))# словарь: \n",
    "    # Group_ID - [(id - title - target),()...]b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c1b60464",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 25# минимальное число документов в группе - 1\n",
    "K = 25# top K слов в документе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0c227fba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11690, 49) (11690,) (11690,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_train = []\n",
    "X_train = []\n",
    "tmp = []\n",
    "groups_train = []\n",
    "for new_group in traingroups_titledata:\n",
    "    docs = traingroups_titledata[new_group]\n",
    "    \n",
    "    top_words = {}\n",
    "    for k, (doc_id, title, target_id) in enumerate(docs):\n",
    "        words_j = set(title.strip().split())\n",
    "        for w in words_j:\n",
    "            if w in top_words.keys():\n",
    "                top_words[w] += 1\n",
    "            else:\n",
    "                top_words[w] = 1\n",
    "\n",
    "                \n",
    "    sorted_list = {k: v for k, v in sorted(top_words.items(), key=lambda kv: kv[1], reverse=True)}\n",
    "    #print(len(sorted_list))\n",
    "    topk_words = list(sorted_list.keys())[0:K-1]\n",
    "    \n",
    "    for k, (doc_id, title, target_id) in enumerate(docs):\n",
    "        y_train.append(target_id)\n",
    "        groups_train.append(new_group)\n",
    "        all_dist = []\n",
    "        words = set(title.strip().split())\n",
    "        tmp.append(len(docs))\n",
    "        bool_tmp = []\n",
    "        for z in topk_words:\n",
    "            bool_tmp.append(int(z in words))\n",
    "            \n",
    "        for j in range(0, len(docs)):\n",
    "            if k == j:\n",
    "                continue\n",
    "            doc_id_j, title_j, target_j = docs[j]\n",
    "            words_j = set(title_j.strip().split())\n",
    "            if len(words.union(words_j)) == 0:\n",
    "                all_dist.append(len(words.intersection(words_j)))\n",
    "            else:\n",
    "                all_dist.append(len(words.intersection(words_j))/len(words.union(words_j)))\n",
    "\n",
    "        X_train.append(sorted(all_dist, reverse=True)[0:N] + bool_tmp)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "groups_train = np.array(groups_train)\n",
    "print (X_train.shape, y_train.shape, groups_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "234522cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16627, 49) (16627,)\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "groups_test = []\n",
    "for new_group in testgroups_titledata:\n",
    "    docs = testgroups_titledata[new_group]\n",
    "    \n",
    "    top_words = {}\n",
    "    for k, (doc_id, title) in enumerate(docs):\n",
    "        words_j = set(title.strip().split())\n",
    "        for w in words_j:\n",
    "            if w in top_words.keys():\n",
    "                top_words[w] += 1\n",
    "            else:\n",
    "                top_words[w] = 1\n",
    "    sorted_list = {k: v for k, v in sorted(top_words.items(), key=lambda kv: kv[1], reverse=True)}\n",
    "    topk_words = list(sorted_list.keys())[0:K-1]\n",
    "    \n",
    "    for k, (doc_id, title) in enumerate(docs):\n",
    "        groups_test.append(new_group)\n",
    "        all_dist = []\n",
    "        words = set(title.strip().split())\n",
    "        \n",
    "        bool_tmp = []\n",
    "        for z in topk_words:\n",
    "            bool_tmp.append(int(z in words))\n",
    "        \n",
    "        for j in range(0, len(docs)):\n",
    "            if k == j:\n",
    "                continue\n",
    "            doc_id_j, title_j = docs[j]\n",
    "            words_j = set(title_j.strip().split())\n",
    "            if len(words.union(words_j)) == 0:\n",
    "                all_dist.append(len(words.intersection(words_j)))\n",
    "            else:\n",
    "                all_dist.append(len(words.intersection(words_j))/len(words.union(words_j)))\n",
    "\n",
    "        X_test.append(sorted(all_dist, reverse=True)[0:N] + bool_tmp)\n",
    "X_test = np.array(X_test)\n",
    "groups_test = np.array(groups_test)\n",
    "print(X_test.shape, groups_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0a1304",
   "metadata": {},
   "source": [
    "# Поиск наилучших параметров XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8e050f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "? xgb.XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cb6199c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.65s/trial, best loss: 0.6362785501352021]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    " \n",
    "trials = Trials()\n",
    " \n",
    "def quality(params, X_train, y_train):\n",
    "    #pipeline.set_params(**params)\n",
    "    pipeline = xgb.XGBClassifier(**params)\n",
    " \n",
    "    score = cross_val_score(estimator=pipeline, X=X_train, y=y_train, groups=groups_train,\n",
    "                            scoring='f1', cv=GroupKFold(n_splits=5), n_jobs=-1) \n",
    "                            #fit_params={'categorical_feature' : 'auto'}\n",
    "    return   {'loss': score.mean(), 'params': params, 'status': STATUS_OK}\n",
    " \n",
    "grid = {\n",
    "        'n_estimators' : scope.int(hp.quniform(label='n_estimators', \n",
    "                        low=50, \n",
    "                        high=500, \n",
    "                        q=1)),\n",
    "        'max_depth' : scope.int(hp.quniform(label='max_depth', \n",
    "                        low=2, \n",
    "                        high=11, \n",
    "                        q=1)),\n",
    "        'learning_rate' : hp.loguniform(label='learning_rate', \n",
    "                        low=-3*np.log(10), \n",
    "                        high=np.log(1)),\n",
    "        'subsample' : hp.uniform(label='subsample', \n",
    "                        low=0.1, \n",
    "                        high=1),\n",
    "        'colsample_bytree' : hp.uniform(label='colsample_bytree', \n",
    "                        low=0.1, \n",
    "                        high=1),\n",
    "        'colsample_bylevel' : hp.uniform(label='colsample_bylevel', \n",
    "                        low=0.1, \n",
    "                        high=1),\n",
    "        'colsample_bynode' : hp.uniform(label='colsample_bynode', \n",
    "                        low=0.1, \n",
    "                        high=1)\n",
    "                }\n",
    "        \n",
    " \n",
    "best = fmin(fn=partial(quality, \n",
    "                       X_train=X_train, y_train=y_train),\n",
    "                space=grid,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=1,\n",
    "                trials=trials,\n",
    "                verbose= 1,\n",
    "                rstate=np.random.default_rng(1),\n",
    "                show_progressbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d84cb811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bylevel': 0.9422139186669864,\n",
       " 'colsample_bynode': 0.8947769179863024,\n",
       " 'colsample_bytree': 0.10622632852938073,\n",
       " 'learning_rate': 0.0047805268897416235,\n",
       " 'max_depth': 7.0,\n",
       " 'n_estimators': 206.0,\n",
       " 'subsample': 0.5591228131751852}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fad14b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_list = np.arange(50, 501, 50)\n",
    "max_depth_list = np.arange(2, 9, 1)\n",
    "learn_rate_list = np.arange(0.01, 1.01, 0.09)\n",
    "subsample_list = np.arange(0.3, 1.01, 0.1)\n",
    "colsample_list = np.arange(0.3, 1.01, 0.1)\n",
    "colsample_by_level_list = np.arange(0.3, 1.01, 0.1)\n",
    "colsample_by_node_list = np.arange(0.3, 1.01, 0.1)\n",
    "\n",
    "best_n = 0\n",
    "best_dep = 0\n",
    "best_learn_rate = 0\n",
    "best_subsample = 0\n",
    "best_colsample = 0\n",
    "best_colsample_by_level = 0\n",
    "best_colsample_by_node = 0\n",
    "\n",
    "par = {'eval_metric': 'logloss'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f9c61",
   "metadata": {},
   "source": [
    "### Подбираем n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a9f3c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0b1c202b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "\n",
    "for n_est in n_estimators_list:\n",
    "    clf = xgb.XGBClassifier(\n",
    "        n_estimators=n_est,\n",
    "        learning_rate = 0.01,\n",
    "        max_depth=5\n",
    "    )\n",
    "    cv_score = cross_val_score(\n",
    "        clf,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        groups=groups_train,\n",
    "        cv =GroupKFold(n_splits=5),\n",
    "        scoring='f1',\n",
    "        fit_params= par\n",
    "    ).mean()\n",
    "    if cv_score > best_score:\n",
    "        best_n = n_est\n",
    "        best_score = cv_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6640b88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 0.6606855164087648)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_n, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9027467",
   "metadata": {},
   "source": [
    "### Подбираем max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6a734dae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "\n",
    "for depth in max_depth_list:\n",
    "    clf = xgb.XGBClassifier(\n",
    "        n_estimators=best_n,\n",
    "        learning_rate = 0.01,\n",
    "        max_depth=depth\n",
    "    )\n",
    "    cv_score = cross_val_score(\n",
    "        clf,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        groups=groups_train,\n",
    "        cv =GroupKFold(n_splits=5),\n",
    "        scoring='f1',\n",
    "        fit_params= par\n",
    "    ).mean()\n",
    "    if cv_score > best_score:\n",
    "        best_dep = depth\n",
    "        best_score = cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c8cdac4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 0.6606855164087648)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dep, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1aba97",
   "metadata": {},
   "source": [
    "### Подбираем learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "428fbdcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "\n",
    "for rate in learn_rate_list:\n",
    "    clf = xgb.XGBClassifier(\n",
    "        n_estimators=best_n,\n",
    "        learning_rate = rate,\n",
    "        max_depth=best_dep\n",
    "    )\n",
    "    cv_score = cross_val_score(\n",
    "        clf,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        groups=groups_train,\n",
    "        cv =GroupKFold(n_splits=5),\n",
    "        scoring='f1',\n",
    "        fit_params= par\n",
    "    ).mean()\n",
    "    if cv_score > best_score:\n",
    "        best_learn_rate = rate\n",
    "        best_score = cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b8889a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01, 0.6606855164087648)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if best_learn_rate >= 1.0:\n",
    "    best_learn_rate = 1.0\n",
    "best_learn_rate, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e1eaa7",
   "metadata": {},
   "source": [
    "### Подбираем subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "74304da0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "\n",
    "for sub in subsample_list:\n",
    "    clf = xgb.XGBClassifier(\n",
    "        n_estimators=best_n,\n",
    "        learning_rate = best_learn_rate,\n",
    "        max_depth=best_dep,\n",
    "        subsample = sub\n",
    "    )\n",
    "    cv_score = cross_val_score(\n",
    "        clf,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        groups=groups_train,\n",
    "        cv =GroupKFold(n_splits=5),\n",
    "        scoring='f1',\n",
    "        fit_params= par\n",
    "    ).mean()\n",
    "    if cv_score > best_score:\n",
    "        best_subsample = sub\n",
    "        best_score = cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cc0c3b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.6606855164087648)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if best_subsample >= 1.0:\n",
    "    best_subsample = 1.0\n",
    "\n",
    "best_subsample, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8bf35e",
   "metadata": {},
   "source": [
    "### Подбираем colsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9584cd00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "\n",
    "for col in colsample_list:\n",
    "    clf = xgb.XGBClassifier(\n",
    "        n_estimators=best_n,\n",
    "        learning_rate = best_learn_rate,\n",
    "        max_depth=best_dep,\n",
    "        subsample = best_subsample,\n",
    "        colsample_bytree = col,\n",
    "    )\n",
    "    cv_score = cross_val_score(\n",
    "        clf,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        groups=groups_train,\n",
    "        cv =GroupKFold(n_splits=5),\n",
    "        scoring='f1',\n",
    "        fit_params= par\n",
    "    ).mean()\n",
    "    if cv_score > best_score:\n",
    "        best_colsample = col\n",
    "        best_score = cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "731d2b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8000000000000003, 0.6615644175163237)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if best_colsample >= 1.0:\n",
    "    best_colsample = 1.0\n",
    "best_colsample, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1a064d59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "\n",
    "for col_level in colsample_by_level_list:\n",
    "    clf = xgb.XGBClassifier(\n",
    "        n_estimators=best_n,\n",
    "        learning_rate = best_learn_rate,\n",
    "        max_depth=best_dep,\n",
    "        subsample = best_subsample,\n",
    "        colsample_bytree = best_colsample,\n",
    "        colsample_bylevel = col_level\n",
    "    )\n",
    "    cv_score = cross_val_score(\n",
    "        clf,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        groups=groups_train,\n",
    "        cv =GroupKFold(n_splits=5),\n",
    "        scoring='f1',\n",
    "        fit_params= par\n",
    "    ).mean()\n",
    "    if cv_score > best_score:\n",
    "        best_colsample_by_level = col_level\n",
    "        best_score = cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2fc8b86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.6615644175163237)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if best_colsample_by_level >= 1.0:\n",
    "    best_colsample_by_level = 1.0\n",
    "best_colsample_by_level, best_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dc7ea5bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "\n",
    "for col_node in colsample_by_node_list:\n",
    "    clf = xgb.XGBClassifier(\n",
    "        n_estimators=best_n,\n",
    "        learning_rate = best_learn_rate,\n",
    "        max_depth=best_dep,\n",
    "        subsample = best_subsample,\n",
    "        colsample_bytree = best_colsample,\n",
    "        colsample_bylevel = best_colsample_by_level,\n",
    "        colsample_bynode = col_node\n",
    "    )\n",
    "    cv_score = cross_val_score(\n",
    "        clf,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        groups=groups_train,\n",
    "        cv =GroupKFold(n_splits=5),\n",
    "        scoring='f1',\n",
    "        fit_params= par\n",
    "    ).mean()\n",
    "    if cv_score > best_score:\n",
    "        best_colsample_by_node = col_node\n",
    "        best_score = cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bac8eb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.6615644175163237)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if best_colsample_by_node >= 1.0:\n",
    "    best_colsample_by_node = 1.0\n",
    "\n",
    "best_colsample_by_node, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24074dc",
   "metadata": {},
   "source": [
    "### Подбираем регуляризацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a2daf985",
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_list = np.arange(0, 2.01, 0.5)\n",
    "L2_list = np.arange(0, 2.01, 0.5)\n",
    "\n",
    "best_L1 = 0\n",
    "best_L2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fb3edd5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "\n",
    "for alpha in L1_list:\n",
    "    for lambda_ in L2_list:\n",
    "        clf = xgb.XGBClassifier(\n",
    "            n_estimators=best_n,\n",
    "            learning_rate = best_learn_rate,\n",
    "            max_depth=best_dep,\n",
    "            subsample = best_subsample,\n",
    "            colsample_bytree = best_colsample,\n",
    "            colsample_bylevel = best_colsample_by_level,\n",
    "            colsample_bynode = best_colsample_by_node,\n",
    "            reg_alpha = alpha,\n",
    "            reg_lambda = lambda_\n",
    "        )\n",
    "        cv_score = cross_val_score(\n",
    "            clf,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            groups=groups_train,\n",
    "            cv =GroupKFold(n_splits=5),\n",
    "            scoring='f1',\n",
    "            fit_params= par\n",
    "        ).mean()\n",
    "        if cv_score > best_score:\n",
    "            best_L1 = alpha\n",
    "            best_L2 = lambda_\n",
    "            best_score = cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8ede34ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.5, 0.6628018336593079)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_L1, best_L2, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f002a0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'n_estimators': best_n, 'max_depth': best_dep, 'learning_rate': best_learn_rate,\n",
    "              'subsample': best_subsample, 'colsample_bytree': best_colsample, \n",
    "              'colsample_bylevel': best_colsample_by_level, 'colsample_bynode': best_colsample_by_node,\n",
    "              'reg_alpha': best_L1, 'reg_lambda': best_L2}\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bdbd0a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6628018336593079"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(**best_params)\n",
    "cv_score = cross_val_score(\n",
    "    clf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    groups=groups_train,\n",
    "    cv =GroupKFold(n_splits=5),\n",
    "    scoring='f1',\n",
    "    fit_params= par\n",
    ").mean()\n",
    "cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54654320",
   "metadata": {},
   "source": [
    "# Формируем y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "877b950b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1.0,\n",
       "              colsample_bynode=1.0, colsample_bytree=0.8000000000000003,\n",
       "              enable_categorical=False, gamma=0, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=150, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0.0, reg_lambda=0.5, scale_pos_weight=1,\n",
       "              subsample=1.0, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train, **par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2f4444e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c7e6dad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11691</td>\n",
       "      <td>130</td>\n",
       "      <td>6710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11692</td>\n",
       "      <td>130</td>\n",
       "      <td>4030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11693</td>\n",
       "      <td>130</td>\n",
       "      <td>5561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11694</td>\n",
       "      <td>130</td>\n",
       "      <td>4055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11695</td>\n",
       "      <td>130</td>\n",
       "      <td>4247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16622</th>\n",
       "      <td>28313</td>\n",
       "      <td>309</td>\n",
       "      <td>16637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16623</th>\n",
       "      <td>28314</td>\n",
       "      <td>309</td>\n",
       "      <td>16759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16624</th>\n",
       "      <td>28315</td>\n",
       "      <td>309</td>\n",
       "      <td>15358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16625</th>\n",
       "      <td>28316</td>\n",
       "      <td>309</td>\n",
       "      <td>17287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16626</th>\n",
       "      <td>28317</td>\n",
       "      <td>309</td>\n",
       "      <td>16026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16627 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pair_id  group_id  doc_id\n",
       "0        11691       130    6710\n",
       "1        11692       130    4030\n",
       "2        11693       130    5561\n",
       "3        11694       130    4055\n",
       "4        11695       130    4247\n",
       "...        ...       ...     ...\n",
       "16622    28313       309   16637\n",
       "16623    28314       309   16759\n",
       "16624    28315       309   15358\n",
       "16625    28316       309   17287\n",
       "16626    28317       309   16026\n",
       "\n",
       "[16627 rows x 3 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5266e746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11691</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11692</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11695</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16622</th>\n",
       "      <td>28313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16623</th>\n",
       "      <td>28314</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16624</th>\n",
       "      <td>28315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16625</th>\n",
       "      <td>28316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16626</th>\n",
       "      <td>28317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16627 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pair_id  target\n",
       "0        11691       1\n",
       "1        11692       0\n",
       "2        11693       1\n",
       "3        11694       1\n",
       "4        11695       0\n",
       "...        ...     ...\n",
       "16622    28313       0\n",
       "16623    28314       1\n",
       "16624    28315       1\n",
       "16625    28316       1\n",
       "16626    28317       1\n",
       "\n",
       "[16627 rows x 2 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({\"pair_id\": test_data[\"pair_id\"], \n",
    "                           \"target\": y_pred})\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cddddcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb029c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11be715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29b2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dae3bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "49c8e218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:34:55] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:34:57] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:35:00] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:35:03] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[05:35:05] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6619074643905811"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(n_estimators = best_n, max_depth = best_dep, learning_rate = best_learn_rate)\n",
    "cv_score = cross_val_score(\n",
    "    clf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    groups=groups_train,\n",
    "    cv =GroupKFold(n_splits=5),\n",
    "    scoring='f1'\n",
    ").mean()\n",
    "cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "4fb9ea71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:39:01] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.01, max_delta_step=0,\n",
       "              max_depth=5, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=300, n_jobs=8,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "2c91ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "5d5fc0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11691</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11692</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11695</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16622</th>\n",
       "      <td>28313</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16623</th>\n",
       "      <td>28314</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16624</th>\n",
       "      <td>28315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16625</th>\n",
       "      <td>28316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16626</th>\n",
       "      <td>28317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16627 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pair_id  target\n",
       "0        11691       1\n",
       "1        11692       0\n",
       "2        11693       1\n",
       "3        11694       1\n",
       "4        11695       0\n",
       "...        ...     ...\n",
       "16622    28313       0\n",
       "16623    28314       0\n",
       "16624    28315       1\n",
       "16625    28316       1\n",
       "16626    28317       1\n",
       "\n",
       "[16627 rows x 2 columns]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({\"pair_id\": test_data[\"pair_id\"], \n",
    "                           \"target\": y_pred})\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "ad3fef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e82f9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
