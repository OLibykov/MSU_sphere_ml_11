{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 28 мая 2022, 08:30   \n",
    "**Штраф за опоздание:** по 1 баллу за 24 часа задержки.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0221, Задание 3] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Реализуем дерево решений (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допишите недостающие части дерева решений. Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn.\n",
    "Внимание: если Вас не устраивает предложенная структура хранения дерева, Вы без потери баллов можете сделать свой класс DecisionTreeClassifier, в котором сами полностью воспроизведете алгоритм дерева решений. Обязательно в нем иметь только функции fit, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=5, criterion='gini'):\n",
    "        \"\"\"\n",
    "        criterion -- критерий расщепления. необходимо релизовать три:\n",
    "        Ошибка классификации, Индекс Джини, Энтропийный критерий\n",
    "        max_depth -- максимальная глубина дерева\n",
    "        min_samples_split -- минимальное число объектов в листе, чтобы сделать новый сплит\n",
    "        \"\"\"\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.num_class = -1\n",
    "        # Для последнего задания\n",
    "        self.feature_importances_ = None\n",
    "        self.criterion = criterion\n",
    "        # Структура, которая описывает дерево\n",
    "        # Представляет словарь, где для  node_id (айдишник узла дерева) храним\n",
    "        # (тип_узла, айдишник признака сплита, порог сплита) если тип NON_LEAF_TYPE\n",
    "        # (тип_узла, предсказание класса, вероятность класса) если тип LEAF_TYPE\n",
    "        # Подразумевается, что у каждого node_id в дереве слева \n",
    "        # узел с айди 2 * node_id + 1, а справа 2 * node_id + 2\n",
    "        self.tree = dict()\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        \"\"\"\n",
    "        Разделяет объекты на 2 множества\n",
    "        x -- матрица объектов\n",
    "        y -- вектор ответов\n",
    "        feature_id -- айдишник признака, по которому делаем сплит\n",
    "        threshold -- порог, по которому делаем сплит\n",
    "        \"\"\"\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "  \n",
    "    def impurity(self, p):\n",
    "        if self.criterion == 'gini':\n",
    "            return 1 - np.sum(p ** 2)\n",
    "        elif self.criterion == 'entropy':\n",
    "            return -np.sum(p * np.log(p+0.01)/np.log(2))\n",
    "        else:\n",
    "            return 1 - np.max(p)\n",
    "\n",
    "    def __gini_F(self, l, r):\n",
    "        return 1 -(l / (l + r)) ** 2 - (r / (l + r)) ** 2\n",
    "\n",
    "    def __entropy_F(self, l, r):\n",
    "        def mylog2(x):\n",
    "            x[np.where(x < 1e-37)] = 1\n",
    "            return np.log2(x)   \n",
    "        return -(l / (l + r)) * mylog2(l / (l + r))  - (r / (l + r)) * mylog2(r / (l + r))\n",
    "\n",
    "    def __misclass_F(self, l, r):\n",
    "        return 1 - np.maximum(l / (l + r), r / (l + r))\n",
    "    \n",
    "    def impurity(self, l, ls, r, rs):\n",
    "        if self.criterion == 'entropy':\n",
    "            F = self.__entropy_F\n",
    "        elif self.criterion == 'misclass':\n",
    "            F = self.__misclass_F\n",
    "        else:\n",
    "            F = self.__gini_F\n",
    "        return F(l, r) - l / (l + r) * F(ls, l - ls) - r / (l + r) * F(rs, r - rs)\n",
    "    \n",
    "    def __find_threshold(self, x, y):\n",
    "        \"\"\"\n",
    "        Находим оптимальный признак и порог для сплита\n",
    "        Здесь используемые разные impurity в зависимости от self.criterion\n",
    "        \"\"\"\n",
    "\n",
    "        x = x.T\n",
    "        s_x = np.sort(x, axis = 1)\n",
    "        s_y = y[x.argsort(axis = 1)]\n",
    "        s_y = (s_y == y[0]).astype(int)\n",
    "        _, occurs = np.bincount(s_y[0])\n",
    "        sumsl = np.cumsum(s_y, axis = 1)\n",
    "        sumsr = occurs - sumsl\n",
    "        len_ = s_y.shape[1]\n",
    "        \n",
    "        l = np.array(np.array(range(len_)) + np.zeros(s_y.shape[0]).reshape(-1, 1))\n",
    "        l[:, 0] += 1\n",
    "        r = len_ - l\n",
    "        impurities = self.impurity(l, sumsl, r, sumsr)\n",
    "        feature_id, threshold_idx = np.unravel_index(np.argmax(impurities), impurities.shape)\n",
    "        \n",
    "        return feature_id, s_x[feature_id, threshold_idx], impurities[feature_id, threshold_idx]\n",
    "\n",
    "        \"\"\"\n",
    "        x = np.asarray(x)\n",
    "        y = np.asarray(y)\n",
    "        arg_sort_x = np.sort(x, axis = 0)\n",
    "        arg_sort_y = y[x.argsort(axis = 0)]\n",
    "        R = y.size\n",
    "        n_class, counts = np.unique(y, return_counts = True)\n",
    "        H = self.impurity(counts/R)\n",
    "        \n",
    "        def count_q(y):\n",
    "            max_Q = 0\n",
    "            max_idx = [0, 0]\n",
    "            for i in range (0, R - 1):\n",
    "                n_class_left, counts_left = np.unique(y[0:i+1], return_counts = True)\n",
    "                n_class_right, counts_right = np.unique(y[i+1:y.size], return_counts = True)\n",
    "                Rl = i + 1\n",
    "                Rr = y.size - Rl\n",
    "                Hl = self.impurity(counts_left/Rl)\n",
    "                Hr = self.impurity(counts_right/Rr)\n",
    "                Q = H - (Hl * Rl / R) - (Hr * Rr / R)\n",
    "                if Q > max_Q:\n",
    "                    max_Q = Q \n",
    "                    max_idx[0] = Q\n",
    "                    max_idx[1] = i\n",
    "            return max_idx\n",
    "        \n",
    "        result = np.apply_along_axis(count_q, 0, arg_sort_y)\n",
    "        result = result.T\n",
    "        idx = int(np.argmax(result[0]))\n",
    "        n_threshold = int(result[1][idx])\n",
    "        res = np.mean(arg_sort_x[n_threshold:n_threshold + 2, idx])\n",
    "        return idx, res\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        x = np.asarray(x)\n",
    "        y = np.asarray(y)\n",
    "        R = y.size\n",
    "        n_class, counts = np.unique(y, return_counts = True)\n",
    "        H = self.impurity(counts/R)\n",
    "        max_Q = 0\n",
    "        max_idx = [0, 0]\n",
    "        for i in range (x.shape[1]):\n",
    "            feature_response = np.hstack((x[:, i].reshape(-1, 1), y.reshape(-1, 1)))\n",
    "            feature_response = feature_response[feature_response[:, 0].argsort()]\n",
    "            Rl = 0\n",
    "            Rr = R\n",
    "            counts_left = np.zeros(counts.size)\n",
    "            counts_right = np.copy(counts) \n",
    "            for j in range (0, R - 1):\n",
    "                Rl += 1\n",
    "                Rr -= 1\n",
    "                idx = feature_response[j, 1]\n",
    "                counts_left[int(idx) == n_class] += 1\n",
    "                counts_right[int(idx) == n_class] -= 1\n",
    "                Hl = self.impurity(counts_left/Rl)\n",
    "                Hr = self.impurity(counts_right/Rr)\n",
    "                Q = H - (Hl * Rl / R) - (Hr * Rr / R)\n",
    "                if Q > max_Q:\n",
    "                    max_Q = Q \n",
    "                    max_idx[0] = i\n",
    "                    max_idx[1] = np.mean(feature_response[j:j+2, 0])\n",
    "        return max_idx[0],  max_idx[1], max_Q\n",
    "        \"\"\"\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        \"\"\"\n",
    "        Делаем новый узел в дереве\n",
    "        Решаем, терминальный он или нет\n",
    "        Если нет, то строим левый узел  с айди 2 * node_id + 1\n",
    "        И правый узел с  айди 2 * node_id + 2\n",
    "        \"\"\"\n",
    "        n_class, counts = np.unique(y, return_counts=True)\n",
    "        if (depth == self.max_depth) or (y.size < self.min_samples_split) or (n_class.size == 1):\n",
    "            p = counts/y.size\n",
    "            self.tree[node_id] = [self.LEAF_TYPE, n_class[counts.argmax()], p]\n",
    "        else:\n",
    "            feature_id, threshold, crit_val = self.__find_threshold(x, y)\n",
    "            x_left, x_right, y_left, y_right = self.__div_samples(x, y, feature_id, threshold)\n",
    "            if (y_left.size == 0) or (y_right.size == 0):\n",
    "                p = counts/y.size\n",
    "                self.tree[node_id] = [self.LEAF_TYPE, n_class[counts.argmax()], p]\n",
    "            else:\n",
    "                self.tree[node_id] = [self.NON_LEAF_TYPE, feature_id, threshold]\n",
    "                self.feature_importances_[feature_id] += crit_val\n",
    "                self.__fit_node(x_left, y_left, 2 * node_id + 1, depth + 1)\n",
    "                self.__fit_node(x_right, y_right, 2 * node_id + 2, depth + 1)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        Рекурсивно строим дерево решений\n",
    "        Начинаем с корня node_id 0\n",
    "        \"\"\"\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(x.shape[1])\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        \"\"\"\n",
    "        Рекурсивно обходим дерево по всем узлам,\n",
    "        пока не дойдем до терминального\n",
    "        \"\"\"\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Вызывает predict для всех объектов из матрицы X\n",
    "        \"\"\"\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"\n",
    "        Возвращает важность признаков\n",
    "        \"\"\"\n",
    "        return self.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n",
      "0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "my_clf.fit(X_train, y_train)\n",
    "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ускоряем дерево решений (2 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine. \n",
    "Для этого используем numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.04 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.7 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Боевое применение (3 балла)\n",
    "\n",
    "На практике Вы познакомились с датасетом Speed Dating Data. В нем каждая пара в быстрых свиданиях характеризуется определенным набором признаков. Задача -- предсказать, произойдет ли матч пары (колонка match). \n",
    "\n",
    "Пример работы с датасетом можете найти в практике пункт 2\n",
    "https://github.com/VVVikulin/ml1.sphere/blob/master/2019-09/lecture_06/pract-trees.ipynb\n",
    "\n",
    "Данные и описания колонок лежат тут\n",
    "https://cloud.mail.ru/public/8nHV/p6J7wY1y1/speed-dating-experiment/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте датасет, обработайте данные, как показано на семинаре или своим собственным способом. Обучите дерево классифкации. В качестве таргета возьмите колонку 'match'. Постарайтесь хорошо обработать признаки, чтобы выбить максимальную точность. Если точность будет близка к случайному гаданию, задание не будет защитано. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>...</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8373</th>\n",
       "      <td>552</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>552</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8375</th>\n",
       "      <td>552</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8376</th>\n",
       "      <td>552</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8377</th>\n",
       "      <td>552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8378 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iid    id  gender  idg  condtn  wave  round  position  positin1  order  \\\n",
       "0       1   1.0       0    1       1     1     10         7       NaN      4   \n",
       "1       1   1.0       0    1       1     1     10         7       NaN      3   \n",
       "2       1   1.0       0    1       1     1     10         7       NaN     10   \n",
       "3       1   1.0       0    1       1     1     10         7       NaN      5   \n",
       "4       1   1.0       0    1       1     1     10         7       NaN      7   \n",
       "...   ...   ...     ...  ...     ...   ...    ...       ...       ...    ...   \n",
       "8373  552  22.0       1   44       2    21     22        14      10.0      5   \n",
       "8374  552  22.0       1   44       2    21     22        13      10.0      4   \n",
       "8375  552  22.0       1   44       2    21     22        19      10.0     10   \n",
       "8376  552  22.0       1   44       2    21     22         3      10.0     16   \n",
       "8377  552   NaN       1   44       2    21     22         2      10.0     15   \n",
       "\n",
       "      ...  attr3_3  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  \\\n",
       "0     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "1     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "2     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "3     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "4     ...      5.0      7.0       7.0     7.0     7.0      NaN      NaN   \n",
       "...   ...      ...      ...       ...     ...     ...      ...      ...   \n",
       "8373  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n",
       "8374  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n",
       "8375  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n",
       "8376  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n",
       "8377  ...      8.0      5.0       7.0     6.0     7.0      9.0      5.0   \n",
       "\n",
       "      intel5_3  fun5_3  amb5_3  \n",
       "0          NaN     NaN     NaN  \n",
       "1          NaN     NaN     NaN  \n",
       "2          NaN     NaN     NaN  \n",
       "3          NaN     NaN     NaN  \n",
       "4          NaN     NaN     NaN  \n",
       "...        ...     ...     ...  \n",
       "8373       9.0     5.0     6.0  \n",
       "8374       9.0     5.0     6.0  \n",
       "8375       9.0     5.0     6.0  \n",
       "8376       9.0     5.0     6.0  \n",
       "8377       9.0     5.0     6.0  \n",
       "\n",
       "[8378 rows x 195 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ML/MSU_sphere_ml_11/hw3/Speed Dating Data.csv', encoding='latin1')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(axis='columns', thresh=8000)\n",
    "df = df.dropna(thresh=84)\n",
    "np.where(pd.isnull(df)) # нет na нет проблем. Всего лишь потеряли 15 процентов данных\n",
    "# и 100+, наверное, не нужных признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>gender</th>\n",
       "      <th>match</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age_o</th>\n",
       "      <th>dec_o</th>\n",
       "      <th>attr_o</th>\n",
       "      <th>sinc_o</th>\n",
       "      <th>intel_o</th>\n",
       "      <th>...</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>amb3_1</th>\n",
       "      <th>dec</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "      <th>like</th>\n",
       "      <th>prob</th>\n",
       "      <th>met</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8371</th>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8372</th>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8373</th>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8376</th>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6913 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iid  gender  match  int_corr  samerace  age_o  dec_o  attr_o  sinc_o  \\\n",
       "30      4       0      0     -0.18         1   27.0      0     6.0     7.0   \n",
       "31      4       0      0     -0.18         1   22.0      0     6.0     5.0   \n",
       "32      4       0      0      0.05         0   22.0      1    10.0    10.0   \n",
       "33      4       0      1     -0.18         1   23.0      1     7.0     7.0   \n",
       "34      4       0      0      0.21         0   24.0      1     8.0     8.0   \n",
       "...   ...     ...    ...       ...       ...    ...    ...     ...     ...   \n",
       "8371  552       1      1      0.59         0   25.0      1     8.0     6.0   \n",
       "8372  552       1      0      0.28         1   24.0      0     8.0     8.0   \n",
       "8373  552       1      0      0.64         0   26.0      1    10.0     5.0   \n",
       "8374  552       1      0      0.71         0   24.0      0     6.0     3.0   \n",
       "8376  552       1      0      0.62         0   22.0      1     5.0     7.0   \n",
       "\n",
       "      intel_o  ...  intel3_1  amb3_1  dec  attr  sinc  intel   fun  like  \\\n",
       "30        8.0  ...       7.0     8.0    0   4.0  10.0    8.0   5.0   6.0   \n",
       "31       10.0  ...       7.0     8.0    0   8.0   7.0    8.0  10.0   8.0   \n",
       "32       10.0  ...       7.0     8.0    0   4.0   7.0    8.0   8.0   4.0   \n",
       "33        7.0  ...       7.0     8.0    1   8.0  10.0    7.0  10.0   8.0   \n",
       "34        9.0  ...       7.0     8.0    0   6.0   9.0    8.0   9.0   7.0   \n",
       "...       ...  ...       ...     ...  ...   ...   ...    ...   ...   ...   \n",
       "8371      7.0  ...       7.0     7.0    1   8.0   7.0    8.0   8.0   7.0   \n",
       "8372      7.0  ...       7.0     7.0    0   7.0   5.0    5.0   5.0   4.0   \n",
       "8373      3.0  ...       7.0     7.0    0   3.0   5.0    5.0   5.0   2.0   \n",
       "8374      7.0  ...       7.0     7.0    0   4.0   6.0    8.0   4.0   4.0   \n",
       "8376      5.0  ...       7.0     7.0    0   4.0   6.0    5.0   4.0   5.0   \n",
       "\n",
       "      prob  met  \n",
       "30     7.0  2.0  \n",
       "31     1.0  1.0  \n",
       "32     1.0  2.0  \n",
       "33    10.0  1.0  \n",
       "34     7.0  2.0  \n",
       "...    ...  ...  \n",
       "8371   6.0  0.0  \n",
       "8372   4.0  0.0  \n",
       "8373   5.0  0.0  \n",
       "8374   4.0  0.0  \n",
       "8376   5.0  0.0  \n",
       "\n",
       "[6913 rows x 46 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['id'], axis = 1)\n",
    "df = df.drop(['idg'], axis = 1)\n",
    "df = df.drop(['condtn'], axis = 1)\n",
    "df = df.drop(['from'], axis = 1)\n",
    "df = df.drop(['round'], axis = 1)\n",
    "df = df.drop(['wave'], axis = 1)\n",
    "df = df.drop(['position'], axis = 1)\n",
    "df = df.drop(['order'], axis = 1)\n",
    "df = df.drop(['partner'], axis = 1)\n",
    "df = df.drop(['pid'], axis = 1)\n",
    "df = df.drop(['field'], axis = 1)\n",
    "df = df.drop(['race_o','race'], axis = 1)\n",
    "df = df.drop(['career'], axis = 1)\n",
    "df = df.drop(['pf_o_att', \n",
    "              'pf_o_sin', 'pf_o_int',\n",
    "              'pf_o_fun', 'pf_o_amb', 'pf_o_sha'], axis = 1)\n",
    "df = df.drop(['sports', 'tvsports', 'dining','museums', 'exercise',\n",
    "              'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv',\n",
    "              'theater', 'movies', 'concerts', 'music', 'shopping', 'yoga'], axis = 1)\n",
    "df = df.drop(['exphappy'], axis = 1)\n",
    "#df = df.drop(['undergra'], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 4.00e+00,  0.00e+00, -1.80e-01, ...,  6.00e+00,  7.00e+00,\n",
       "          2.00e+00],\n",
       "        [ 4.00e+00,  0.00e+00, -1.80e-01, ...,  8.00e+00,  1.00e+00,\n",
       "          1.00e+00],\n",
       "        [ 4.00e+00,  0.00e+00,  5.00e-02, ...,  4.00e+00,  1.00e+00,\n",
       "          2.00e+00],\n",
       "        ...,\n",
       "        [ 5.52e+02,  1.00e+00,  6.40e-01, ...,  2.00e+00,  5.00e+00,\n",
       "          0.00e+00],\n",
       "        [ 5.52e+02,  1.00e+00,  7.10e-01, ...,  4.00e+00,  4.00e+00,\n",
       "          0.00e+00],\n",
       "        [ 5.52e+02,  1.00e+00,  6.20e-01, ...,  5.00e+00,  5.00e+00,\n",
       "          0.00e+00]]),\n",
       " array([0, 0, 0, ..., 0, 0, 0], dtype=int64))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(df.drop(['match'], axis = 1))\n",
    "y = np.array(df['match'])\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>gender</th>\n",
       "      <th>match</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age_o</th>\n",
       "      <th>dec_o</th>\n",
       "      <th>attr_o</th>\n",
       "      <th>sinc_o</th>\n",
       "      <th>intel_o</th>\n",
       "      <th>...</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>amb3_1</th>\n",
       "      <th>dec</th>\n",
       "      <th>attr</th>\n",
       "      <th>sinc</th>\n",
       "      <th>intel</th>\n",
       "      <th>fun</th>\n",
       "      <th>like</th>\n",
       "      <th>prob</th>\n",
       "      <th>met</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8371</th>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8372</th>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8373</th>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8374</th>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8376</th>\n",
       "      <td>552</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6913 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iid  gender  match  int_corr  samerace  age_o  dec_o  attr_o  sinc_o  \\\n",
       "30      4       0      0     -0.18         1   27.0      0     6.0     7.0   \n",
       "31      4       0      0     -0.18         1   22.0      0     6.0     5.0   \n",
       "32      4       0      0      0.05         0   22.0      1    10.0    10.0   \n",
       "33      4       0      1     -0.18         1   23.0      1     7.0     7.0   \n",
       "34      4       0      0      0.21         0   24.0      1     8.0     8.0   \n",
       "...   ...     ...    ...       ...       ...    ...    ...     ...     ...   \n",
       "8371  552       1      1      0.59         0   25.0      1     8.0     6.0   \n",
       "8372  552       1      0      0.28         1   24.0      0     8.0     8.0   \n",
       "8373  552       1      0      0.64         0   26.0      1    10.0     5.0   \n",
       "8374  552       1      0      0.71         0   24.0      0     6.0     3.0   \n",
       "8376  552       1      0      0.62         0   22.0      1     5.0     7.0   \n",
       "\n",
       "      intel_o  ...  intel3_1  amb3_1  dec  attr  sinc  intel   fun  like  \\\n",
       "30        8.0  ...       7.0     8.0    0   4.0  10.0    8.0   5.0   6.0   \n",
       "31       10.0  ...       7.0     8.0    0   8.0   7.0    8.0  10.0   8.0   \n",
       "32       10.0  ...       7.0     8.0    0   4.0   7.0    8.0   8.0   4.0   \n",
       "33        7.0  ...       7.0     8.0    1   8.0  10.0    7.0  10.0   8.0   \n",
       "34        9.0  ...       7.0     8.0    0   6.0   9.0    8.0   9.0   7.0   \n",
       "...       ...  ...       ...     ...  ...   ...   ...    ...   ...   ...   \n",
       "8371      7.0  ...       7.0     7.0    1   8.0   7.0    8.0   8.0   7.0   \n",
       "8372      7.0  ...       7.0     7.0    0   7.0   5.0    5.0   5.0   4.0   \n",
       "8373      3.0  ...       7.0     7.0    0   3.0   5.0    5.0   5.0   2.0   \n",
       "8374      7.0  ...       7.0     7.0    0   4.0   6.0    8.0   4.0   4.0   \n",
       "8376      5.0  ...       7.0     7.0    0   4.0   6.0    5.0   4.0   5.0   \n",
       "\n",
       "      prob  met  \n",
       "30     7.0  2.0  \n",
       "31     1.0  1.0  \n",
       "32     1.0  2.0  \n",
       "33    10.0  1.0  \n",
       "34     7.0  2.0  \n",
       "...    ...  ...  \n",
       "8371   6.0  0.0  \n",
       "8372   4.0  0.0  \n",
       "8373   5.0  0.0  \n",
       "8374   4.0  0.0  \n",
       "8376   5.0  0.0  \n",
       "\n",
       "[6913 rows x 46 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбейте датасет на трейн и валидацию. Подберите на валидации оптимальный критерий  информативности. \n",
    "Постройте графики зависимости точности на валидации от глубины дерева, от минимального числа объектов для сплита. \n",
    "Какой максимальной точности удалось достигнуть?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_split = 1, max_depth =  2, criterion =  gini\n",
      "f1_score = 0.9389732465654376\n",
      "\n",
      "min_samples_split = 5, max_depth =  2, criterion =  gini\n",
      "f1_score = 0.8857060185185185\n",
      "\n",
      "min_samples_split = 10, max_depth =  2, criterion =  gini\n",
      "f1_score = 0.8246771938017193\n",
      "\n",
      "min_samples_split = 15, max_depth =  2, criterion =  gini\n",
      "f1_score = 0.824678951253314\n",
      "\n",
      "min_samples_split = 20, max_depth =  2, criterion =  gini\n",
      "f1_score = 0.8818256909295412\n",
      "\n",
      "min_samples_split = 1, max_depth =  4, criterion =  gini\n",
      "f1_score = 0.9418402777777778\n",
      "\n",
      "min_samples_split = 5, max_depth =  4, criterion =  gini\n",
      "f1_score = 0.8874674243793685\n",
      "\n",
      "min_samples_split = 10, max_depth =  4, criterion =  gini\n",
      "f1_score = 0.8838505889973488\n",
      "\n",
      "min_samples_split = 15, max_depth =  4, criterion =  gini\n",
      "f1_score = 0.9434317129629629\n",
      "\n",
      "min_samples_split = 20, max_depth =  4, criterion =  gini\n",
      "f1_score = 0.82467794699526\n",
      "\n",
      "min_samples_split = 1, max_depth =  5, criterion =  gini\n",
      "f1_score = 0.8858753615328995\n",
      "\n",
      "min_samples_split = 5, max_depth =  5, criterion =  gini\n",
      "f1_score = 0.8789316075158672\n",
      "\n",
      "min_samples_split = 10, max_depth =  5, criterion =  gini\n",
      "f1_score = 0.8246788257210573\n",
      "\n",
      "min_samples_split = 15, max_depth =  5, criterion =  gini\n",
      "f1_score = 0.8246796416807262\n",
      "\n",
      "min_samples_split = 20, max_depth =  5, criterion =  gini\n",
      "f1_score = 0.8246767544388206\n",
      "\n",
      "min_samples_split = 1, max_depth =  8, criterion =  gini\n",
      "f1_score = 0.8845729643689243\n",
      "\n",
      "min_samples_split = 5, max_depth =  8, criterion =  gini\n",
      "f1_score = 0.8839945117297341\n",
      "\n",
      "min_samples_split = 10, max_depth =  8, criterion =  gini\n",
      "f1_score = 0.9428530092592592\n",
      "\n",
      "min_samples_split = 15, max_depth =  8, criterion =  gini\n",
      "f1_score = 0.8815104166666666\n",
      "\n",
      "min_samples_split = 20, max_depth =  8, criterion =  gini\n",
      "f1_score = 0.8858759891941833\n",
      "\n",
      "min_samples_split = 1, max_depth =  10, criterion =  gini\n",
      "f1_score = 0.8246778842291315\n",
      "\n",
      "min_samples_split = 5, max_depth =  10, criterion =  gini\n",
      "f1_score = 0.8852971599582228\n",
      "\n",
      "min_samples_split = 10, max_depth =  10, criterion =  gini\n",
      "f1_score = 0.8811018719370128\n",
      "\n",
      "min_samples_split = 15, max_depth =  10, criterion =  gini\n",
      "f1_score = 0.8246783235920302\n",
      "\n",
      "min_samples_split = 20, max_depth =  10, criterion =  gini\n",
      "f1_score = 0.8816808267052302\n",
      "\n",
      "min_samples_split = 1, max_depth =  15, criterion =  gini\n",
      "f1_score = 0.8246780097613883\n",
      "\n",
      "min_samples_split = 5, max_depth =  15, criterion =  gini\n",
      "f1_score = 0.9440104166666666\n",
      "\n",
      "min_samples_split = 10, max_depth =  15, criterion =  gini\n",
      "f1_score = 0.8246793278500842\n",
      "\n",
      "min_samples_split = 15, max_depth =  15, criterion =  gini\n",
      "f1_score = 0.9419849537037037\n",
      "\n",
      "min_samples_split = 20, max_depth =  15, criterion =  gini\n",
      "f1_score = 0.884138183397606\n",
      "\n",
      "min_samples_split = 1, max_depth =  2, criterion =  entropy\n",
      "f1_score = 0.8844039351851851\n",
      "\n",
      "min_samples_split = 5, max_depth =  2, criterion =  entropy\n",
      "f1_score = 0.8805231054671809\n",
      "\n",
      "min_samples_split = 10, max_depth =  2, criterion =  entropy\n",
      "f1_score = 0.879510938880855\n",
      "\n",
      "min_samples_split = 15, max_depth =  2, criterion =  entropy\n",
      "f1_score = 0.8246785746565437\n",
      "\n",
      "min_samples_split = 20, max_depth =  2, criterion =  entropy\n",
      "f1_score = 0.9430224150397687\n",
      "\n",
      "min_samples_split = 1, max_depth =  4, criterion =  entropy\n",
      "f1_score = 0.8246782608259018\n",
      "\n",
      "min_samples_split = 5, max_depth =  4, criterion =  entropy\n",
      "f1_score = 0.8246785746565437\n",
      "\n",
      "min_samples_split = 10, max_depth =  4, criterion =  entropy\n",
      "f1_score = 0.9437210648148149\n",
      "\n",
      "min_samples_split = 15, max_depth =  4, criterion =  entropy\n",
      "f1_score = 0.8246798299791115\n",
      "\n",
      "min_samples_split = 20, max_depth =  4, criterion =  entropy\n",
      "f1_score = 0.8246790767855708\n",
      "\n",
      "min_samples_split = 1, max_depth =  5, criterion =  entropy\n",
      "f1_score = 0.8845723367076405\n",
      "\n",
      "min_samples_split = 5, max_depth =  5, criterion =  entropy\n",
      "f1_score = 0.8246772565678477\n",
      "\n",
      "min_samples_split = 10, max_depth =  5, criterion =  entropy\n",
      "f1_score = 0.8799189814814815\n",
      "\n",
      "min_samples_split = 15, max_depth =  5, criterion =  entropy\n",
      "f1_score = 0.824677633164618\n",
      "\n",
      "min_samples_split = 20, max_depth =  5, criterion =  entropy\n",
      "f1_score = 0.8826678240740741\n",
      "\n",
      "min_samples_split = 1, max_depth =  8, criterion =  entropy\n",
      "f1_score = 0.8832735799791115\n",
      "\n",
      "min_samples_split = 5, max_depth =  8, criterion =  entropy\n",
      "f1_score = 0.8839699074074074\n",
      "\n",
      "min_samples_split = 10, max_depth =  8, criterion =  entropy\n",
      "f1_score = 0.8246785746565438\n",
      "\n",
      "min_samples_split = 15, max_depth =  8, criterion =  entropy\n",
      "f1_score = 0.8246788257210573\n",
      "\n",
      "min_samples_split = 20, max_depth =  8, criterion =  entropy\n",
      "f1_score = 0.9402488425925926\n",
      "\n",
      "min_samples_split = 1, max_depth =  10, criterion =  entropy\n",
      "f1_score = 0.8835602328874428\n",
      "\n",
      "min_samples_split = 5, max_depth =  10, criterion =  entropy\n",
      "f1_score = 0.9375\n",
      "\n",
      "min_samples_split = 10, max_depth =  10, criterion =  entropy\n",
      "f1_score = 0.8822337962962963\n",
      "\n",
      "min_samples_split = 15, max_depth =  10, criterion =  entropy\n",
      "f1_score = 0.8831018518518517\n",
      "\n",
      "min_samples_split = 20, max_depth =  10, criterion =  entropy\n",
      "f1_score = 0.8246786374226721\n",
      "\n",
      "min_samples_split = 1, max_depth =  15, criterion =  entropy\n",
      "f1_score = 0.8812210648148149\n",
      "\n",
      "min_samples_split = 5, max_depth =  15, criterion =  entropy\n",
      "f1_score = 0.8246776959307464\n",
      "\n",
      "min_samples_split = 10, max_depth =  15, criterion =  entropy\n",
      "f1_score = 0.8246785118904153\n",
      "\n",
      "min_samples_split = 15, max_depth =  15, criterion =  entropy\n",
      "f1_score = 0.883849647505423\n",
      "\n",
      "min_samples_split = 20, max_depth =  15, criterion =  entropy\n",
      "f1_score = 0.8835358796296297\n",
      "\n",
      "min_samples_split = 1, max_depth =  2, criterion =  misclass\n",
      "f1_score = 0.8246789512533139\n",
      "\n",
      "min_samples_split = 5, max_depth =  2, criterion =  misclass\n",
      "f1_score = 0.824677319333976\n",
      "\n",
      "min_samples_split = 10, max_depth =  2, criterion =  misclass\n",
      "f1_score = 0.8246787629549289\n",
      "\n",
      "min_samples_split = 15, max_depth =  2, criterion =  misclass\n",
      "f1_score = 0.8246776959307464\n",
      "\n",
      "min_samples_split = 20, max_depth =  2, criterion =  misclass\n",
      "f1_score = 0.824679767212983\n",
      "\n",
      "min_samples_split = 1, max_depth =  4, criterion =  misclass\n",
      "f1_score = 0.8627216899654536\n",
      "\n",
      "min_samples_split = 5, max_depth =  4, criterion =  misclass\n",
      "f1_score = 0.8550484680043384\n",
      "\n",
      "min_samples_split = 10, max_depth =  4, criterion =  misclass\n",
      "f1_score = 0.8747373237527115\n",
      "\n",
      "min_samples_split = 15, max_depth =  4, criterion =  misclass\n",
      "f1_score = 0.849266452257572\n",
      "\n",
      "min_samples_split = 20, max_depth =  4, criterion =  misclass\n",
      "f1_score = 0.8376985292640797\n",
      "\n",
      "min_samples_split = 1, max_depth =  5, criterion =  misclass\n",
      "f1_score = 0.9009102343938299\n",
      "\n",
      "min_samples_split = 5, max_depth =  5, criterion =  misclass\n",
      "f1_score = 0.8485494747730377\n",
      "\n",
      "min_samples_split = 10, max_depth =  5, criterion =  misclass\n",
      "f1_score = 0.863884997388929\n",
      "\n",
      "min_samples_split = 15, max_depth =  5, criterion =  misclass\n",
      "f1_score = 0.895130729292199\n",
      "\n",
      "min_samples_split = 20, max_depth =  5, criterion =  misclass\n",
      "f1_score = 0.919143418092713\n",
      "\n",
      "min_samples_split = 1, max_depth =  8, criterion =  misclass\n",
      "f1_score = 0.8787761985819876\n",
      "\n",
      "min_samples_split = 5, max_depth =  8, criterion =  misclass\n",
      "f1_score = 0.8822572080621836\n",
      "\n",
      "min_samples_split = 10, max_depth =  8, criterion =  misclass\n",
      "f1_score = 0.9272280092592592\n",
      "\n",
      "min_samples_split = 15, max_depth =  8, criterion =  misclass\n",
      "f1_score = 0.9458912037037037\n",
      "\n",
      "min_samples_split = 20, max_depth =  8, criterion =  misclass\n",
      "f1_score = 0.8867388979272114\n",
      "\n",
      "min_samples_split = 1, max_depth =  10, criterion =  misclass\n",
      "f1_score = 0.8721224868442196\n",
      "\n",
      "min_samples_split = 5, max_depth =  10, criterion =  misclass\n",
      "f1_score = 0.931730411946654\n",
      "\n",
      "min_samples_split = 10, max_depth =  10, criterion =  misclass\n",
      "f1_score = 0.8711092532337109\n",
      "\n",
      "min_samples_split = 15, max_depth =  10, criterion =  misclass\n",
      "f1_score = 0.8968595595324175\n",
      "\n",
      "min_samples_split = 20, max_depth =  10, criterion =  misclass\n",
      "f1_score = 0.9046742563469109\n",
      "\n",
      "min_samples_split = 1, max_depth =  15, criterion =  misclass\n",
      "f1_score = 0.9236178270868484\n",
      "\n",
      "min_samples_split = 5, max_depth =  15, criterion =  misclass\n",
      "f1_score = 0.8865929039125894\n",
      "\n",
      "min_samples_split = 10, max_depth =  15, criterion =  misclass\n",
      "f1_score = 0.9243415205471198\n",
      "\n",
      "min_samples_split = 15, max_depth =  15, criterion =  misclass\n",
      "f1_score = 0.8912145622439142\n",
      "\n",
      "min_samples_split = 20, max_depth =  15, criterion =  misclass\n",
      "f1_score = 0.933883101851852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits = 3, shuffle = True)\n",
    "\n",
    "min_samples_range = [1, 5, 10, 15, 20]\n",
    "depth_range = [2, 4, 5, 8, 10, 15]\n",
    "crit_range = ['gini', 'entropy', 'misclass']\n",
    "\n",
    "plot_dict = {'gini' : [ [i for i in range(21)] for j in range(16) ],\n",
    "             'entropy' : [ [i for i in range(21)] for j in range(16) ],\n",
    "             'misclass' : [ [i for i in range(21)] for j in range(16) ]}\n",
    "\n",
    "best_model = {}\n",
    "max_score = 0.0\n",
    "\n",
    "for crit in crit_range:\n",
    "    for depth in depth_range:\n",
    "        for min_samples in min_samples_range:\n",
    "            clf = MyDecisionTreeClassifier(min_samples_split = min_samples, max_depth = depth, criterion = crit)\n",
    "            ind = kf.split(X)\n",
    "            scores = []\n",
    "            for train_ind, test_ind in ind:\n",
    "                clf.fit(X[train_ind], y[train_ind])\n",
    "                scores.append(accuracy_score(y[test_ind], clf.predict(X[test_ind])))\n",
    "            score = np.mean(np.array(scores))\n",
    "            \n",
    "            if score > max_score:\n",
    "                best_model = {'min_samples_split' : min_samples, 'max_depth' : depth, 'criterion' : crit}\n",
    "                max_score = score\n",
    "                \n",
    "            print('''min_samples_split = {}, max_depth =  {}, criterion =  {}\\nf1_score = {}\\n'''\\\n",
    "                                        .format(min_samples, depth, crit, score))\n",
    "            \n",
    "            plot_dict[crit][depth][min_samples] = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_split': 15, 'max_depth': 8, 'criterion': 'misclass'}\n",
      "0.9458912037037037\n"
     ]
    }
   ],
   "source": [
    "print(best_model)\n",
    "print(max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = plot_dict[best_model['criterion']]\n",
    "\n",
    "scores_from_min_sample = [scores[best_model['max_depth']][min_samples] for min_samples in min_samples_range]\n",
    "scores_from_max_depth = [scores[max_depth][best_model['min_samples_split']] for max_depth in depth_range]\n",
    "\n",
    "plt.plot(min_samples_range, scores_from_min_sample)\n",
    "\n",
    "plt.xlim(0, 25)\n",
    "plt.ylim(0.7, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(depth_range, scores_from_max_depth)\n",
    "plt.xlim(0, 20)\n",
    "plt.ylim(0.7, 1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Находим самые важные признаки (2 балла)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По построенному дереву  легко понять, какие признаки лучше всего помогли решить задачу. Часто это бывает нужно  не только  для сокращения размерности в данных, но и для лучшего понимания прикладной задачи. Например, Вы хотите понять, какие признаки стоит еще конструировать -- для этого нужно понимать, какие из текущих лучше всего работают в дереве. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой метод -- посчитать число сплитов, где использовался данные признак. Это не лучший вариант, так как по признаку который принимает всего 2 значения, но который почти точно разделяет выборку, число сплитов будет очень 1, но при этом признак сам очень хороший. \n",
    "В этом задании предлагается для каждого признака считать суммарный gain (в лекции обозначено как Q) при использовании этого признака в сплите. Тогда даже у очень хороших признаков с маленьким число сплитов это значение должно быть довольно высоким.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализовать это довольно просто: создаете словарь номер фичи : суммарный гейн и добавляете в нужную фичу каждый раз, когда используете ее при построении дерева. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте функционал, который определяет значения feature importance. Обучите дерево на датасете Speed Dating Data.\n",
    "Выведите 10 главных фичей по важности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n",
    "\n",
    "samp = best_model['min_samples_split']\n",
    "depth = best_model['max_depth']\n",
    "crit = best_model['criterion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mytree = MyDecisionTreeClassifier(min_samples_split = samp, max_depth = depth, criterion = crit)\n",
    "mytree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9075144508670521\n"
     ]
    }
   ],
   "source": [
    "feat_imp = mytree.get_feature_importance()\n",
    "sorted_indices = np.argsort(-feat_imp)\n",
    "y_pred = mytree.predict(X_test)\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iid' 'dec' 'dec_o' 'int_corr' 'gender' 'age_o' 'fun_o' 'intel' 'sinc_o'\n",
      " 'imprelig']\n"
     ]
    }
   ],
   "source": [
    "final_df = df.drop(['match'], axis = 1)\n",
    "features = final_df.columns.values\n",
    "imp_feat = features[sorted_indices[:10]]\n",
    "print(imp_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Какие аспекты обучения деревьев решений Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
